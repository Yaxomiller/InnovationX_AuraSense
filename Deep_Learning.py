# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zaJi_zK5UvHwvGItoBpURGky1ipEGAyi
"""

import numpy as np
import pandas as pd
import os

from numpy import *
from random import *
import matplotlib.pyplot as plt

from glob import glob


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, Flatten
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image

from IPython.display import HTML

# image_size = [224, 224]
# vgg = VGG16(input_shape = image_size + [3], weights = 'imagenet', include_top =  False)
# for layer in vgg.layers:
#     layer.trainable = False

# folders = glob('/kaggle/input/tomato/New Plant Diseases Dataset(Augmented)/train/*')
# print(folders)

!pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets list

! kaggle datasets download -d vipoooool/new-plant-diseases-dataset

!unzip new-plant-diseases-dataset.zip

# BATCH_SIZE = 32
# IMAGE_SIZE = 256
# CHANNELS=3
# EPOCHS=50

base_dir = r"/content/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)"
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "valid")

# base_dir = "/kaggle/input/potato/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)"
# train_dir=os.path.join(base_dir, "train")
# test_dir= os.path.join(base_dir, "test")


image_size = 224
target_size = (image_size, image_size)
input_shape = (image_size, image_size, 3)

batch_size = 32
epochs = 25

# dataset = tf.keras.preprocessing.image_dataset_from_directory(
#     directory_name,
#     seed=None,
#     shuffle=True,
#     image_size=(IMAGE_SIZE,IMAGE_SIZE),
#     batch_size=BATCH_SIZE
# )

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,
                                                             shear_range = 0.2,
                                                             zoom_range = 0.2,
                                                             width_shift_range = 0.2,
                                                             height_shift_range = 0.2,
                                                             fill_mode="nearest")

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)

train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size = (image_size, image_size),
                                               batch_size = batch_size,
                                               class_mode = "categorical")

test_data = test_datagen.flow_from_directory(test_dir,
                                             target_size = (image_size, image_size),
                                             batch_size = batch_size,
                                             class_mode = "categorical")

# print(dataset.shape())
# dataset.head()
# class_names = dataset.class_names
# class_names

# for image_batch, labels_batch in dataset.take(1):
#     print(image_batch.shape)
#     print(labels_batch.numpy())


# print(train_data)
categories = list(train_data.class_indices.keys())
print(train_data.class_indices)

import json
with open('class_indices.json','w') as f:
  json.dump(train_data.class_indices, f)

from IPython.display import FileLink
FileLink(r'class_indices.json')

# plt.figure(figsize=(10, 10))
# for image_batch, labels_batch in dataset.take(1):
#     for i in range(12):
#         ax = plt.subplot(3, 4, i + 1)
#         plt.imshow(image_batch[i].numpy().astype("uint8"))
#         plt.title(class_names[labels_batch[i]])
#         plt.axis("off")


base_model = tf.keras.applications.MobileNet(weights = "imagenet",
                                             include_top = False,
                                             input_shape = input_shape)

base_model.trainable = False

inputs = tf.keras.Input(shape = input_shape)

x = base_model(inputs, training = False)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.2)(x) #regularisation technique to prevent overfitting
x = tf.keras.layers.Dense(len(categories),
                          activation="softmax")(x)

model = keras.Model(inputs = inputs,
                    outputs = x,
                    name="LeafDisease_MobileNet")

optimizer = tf.keras.optimizers.Adam()#updates learning rate / used instead of usual gradient descent

model.compile(optimizer = optimizer,
              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),
              metrics=[keras.metrics.CategoricalAccuracy(),
                       'accuracy'])

!mkdir -p saved_model
model.save('saved_model/my_model')

history = model.fit(train_data,
                    validation_data=test_data,
                    epochs=epochs,
                    steps_per_epoch=150,
                    validation_steps=100)

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

fig = plt.figure(figsize=(10,6))
plt.plot(epochs,loss,c="red",label="Training")
plt.plot(epochs,val_loss,c="blue",label="Validation")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()


# acc = history.history['categorical_accuracy']
# val_acc = history.history['val_categorical_accuracy']

# epochs = range(len(acc))

# fig = plt.figure(figsize=(10,6))
# plt.plot(epochs,acc,c="red",label="Training")
# plt.plot(epochs,val_acc,c="blue",label="Validation")
# plt.xlabel("Epochs")
# plt.ylabel("Accuracy")
# plt.legend()

acc = history.history['categorical_accuracy']
val_acc = history.history['val_categorical_accuracy']

epochs = range(len(acc))
fig = plt.figure(figsize=(10,6))
plt.plot(epochs,acc,c="red",label="Training")
plt.plot(epochs,val_acc,c="blue",label="Validation")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

# #model.save('plant_disease')
# from tensorflow.keras.models import load_model
# model = load_model('plant_disease')

# import tensorflow as tf

# # Convert the model
# converter = tf.lite.TFLiteConverter.from_keras_model(model)
# tflite_model = converter.convert()

# # Save the TFLite model
# with open('model.tflite', 'wb') as f:
#     f.write(tflite_model)

# valid_number=train_data.samples
# pred=model.predict(train_data,steps=valid_number//batch_size)
# final_predict=np.argmax(pred,axis=1)
# true_data=train_data.classes

class_names = list(test_data.class_indices.keys())

# plt.figure(figsize=(30,30))
# number_images=(5,5)
# for i in range(1,(number_images[0]*number_images[1])+1):
#     plt.subplot(number_images[0],number_images[1],i)
#     plt.axis("off")

#     true_label = class_name[train_data.classes[i]]
#     predicted_label = class_name[final_predict[i]]

#     color="green"
#     if true_label != predicted_label:
#         color="red"

#     plt.title(f"True: {true_label}\nPredicted: {predicted_label}", color=color)
#     plt.imshow(plt.imread(train_data.filepaths[i]))
# plt.show()

# class_names=os.listdir(train_dir)
# print(class_names)

# from tensorflow.keras.preprocessing import image
# # Set the figure size for the plot
# plt.figure(figsize=(15, 15))

# # Load the trained model
# model = load_model('/content/plant_disease')

# # Load and preprocess the image
# img_path = '/content/test/test/AppleCedarRust1.JPG'
# img = image.load_img(img_path, target_size=(224, 224))
# img = image.img_to_array(img)
# img = np.expand_dims(img, axis=0)

# # Predict the class probabilities
# probs = model.predict(img)[0]

# # Get the predicted class index and name
# pred_class_prob = np.argmax(probs)
# pred_class_name = class_names[pred_class_prob]

# # Print the predicted class name and probability
# print(f'Predicted class: {pred_class_name}')
# print(f'Probability: {probs[pred_class_prob]}')

# # Display the image with the predicted class and probability
# plt.imshow(img[0]/255.)
# plt.axis('off')
# plt.text(10, 20, f'Predicted class: {pred_class_name}\nProbability: {probs[pred_class_prob]:.2f}', fontsize=20, color='red', bbox=dict(facecolor='white', alpha=0.8))
# plt.show()

import numpy as np

# print(image_batch)
# print(label_batch)
print(label_batch.shape)
print(image_batch.shape)


for image_batch, label_batch in test_data:
    first_image = image_batch[4]
    first_label = int(label_batch[1][1])

    print("first image to predict")
    plt.imshow(first_image)
    print("actual label:",class_names[first_label])
    print(label )
    batch_prediction = model.predict(image_batch)
    print("predicted label:",class_names[np.argmax(batch_prediction[4])])
    break

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i])
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class,confidence

plt.figure(figsize=(15, 15))
for images, labels in test_data:
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i])

        predicted_class, confidence = predict(model, images[i])
        actual_class = class_names[int(labels[i].argmax())]

        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")
    break

